{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made with Julia 1.7.3\n",
    "using DataFrames, CSV\n",
    "# Prevent Makie from open an external window to display graphs\n",
    "# Makie.inline!(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data\n",
    "### File Parser Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readtransformfile"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    readtransformfile(filename)\n",
    "\n",
    "Create a dataframe with transform tracking data from `filename`\n",
    "\"\"\"\n",
    "function readtransformfile(filename)\n",
    "    # Get the length of the file\n",
    "    filelength = filesize(filename)\n",
    "    # Construct empty matrix matching the length of the file\n",
    "    # One column is one log, ie col 1 is:\n",
    "    # controller pos [x,y,z], rot [x,y,z,w], headset pos [x,y,z], rot [x,y,z,w] (14 values)\n",
    "    data_matrix = Matrix{Float32}(undef, 14, filelength ÷ 4 ÷ 14)\n",
    "\n",
    "    # Open data file and read the file into the array\n",
    "    open(filename) do dataFile\n",
    "        read!(dataFile, data_matrix)\n",
    "    end\n",
    "\n",
    "    # BAD WAY TO DO IT (hcat generates tooons of intermediate arrays):\n",
    "    # while !eof(dataFile)\n",
    "    #     data_matrix = hcat(data_matrix, [x for x in reinterpret(Float32, read(dataFile, 4*14))])\n",
    "    # end\n",
    "\n",
    "    # Rotate the matrix so the columns are one variable, ie col1 = controller position x component\n",
    "    data_matrix = permutedims(data_matrix, (2,1))\n",
    "\n",
    "    # Construct the data frame\n",
    "    col_names = [\"c_pos_x\", \"c_pos_y\", \"c_pos_z\",\n",
    "                \"c_rot_x\", \"c_rot_y\", \"c_rot_z\", \"c_rot_w\",\n",
    "                \"h_pos_x\", \"h_pos_y\", \"h_pos_z\",\n",
    "                \"h_rot_x\", \"h_rot_y\", \"h_rot_z\", \"h_rot_w\"]\n",
    "    return DataFrame(data_matrix, col_names)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readlogfile"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    readlogfile(filename)\n",
    "\n",
    "Create a dataframe with log data from `filename`\n",
    "\"\"\"\n",
    "function readlogfile(filename)\n",
    "    # Vectors to hold the parsed components of each log\n",
    "    entities = String[]\n",
    "    tags = String[]\n",
    "    abstimes = Vector{Tuple{Int,Int,Int}}()\n",
    "    reltimes = Float64[]\n",
    "    messages = String[]\n",
    "\n",
    "    # Open data file and iterate over each line\n",
    "    open(filename) do logFile\n",
    "        for line in eachline(logFile)\n",
    "            # If the line has a |, then it's probably a log\n",
    "            if contains(line, \"|\")\n",
    "                # Parse the line for the different parts of the log using regex\n",
    "                entity_match = match(r\"^[A-Z ]+\", line)\n",
    "                push!(entities, strip(entity_match.match))\n",
    "                tag_match = match(r\"[A-Z]+ ?[A-Z]*\", line, length(entity_match.match)+1)\n",
    "                push!(tags, rstrip(tag_match.match))\n",
    "                abstime_match = match(r\"(\\d{1,2}):(\\d{1,2}):(\\d{1,2})\", line, tag_match.offset + length(tag_match.match))\n",
    "                push!(abstimes, Tuple(parse.(UInt8, abstime_match.captures)))\n",
    "                reltime_match = match(r\"[\\d\\.]+\", line, abstime_match.offset + length(abstime_match.match))\n",
    "                push!(reltimes, parse(Float64, reltime_match.match))\n",
    "                message_match = match(r\"[^\\|]+$\", line, reltime_match.offset + length(reltime_match.match))\n",
    "                push!(messages, message_match.match)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Construct and return the dataframe using the vectors\n",
    "    return DataFrame(entity=entities,\n",
    "                     tag=tags,\n",
    "                     abstime=abstimes,\n",
    "                     reltime=reltimes,\n",
    "                     message=messages)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in files, put dataframes in dict\n",
    "this currently does not support handling Guest logs\n",
    "User 121 has only an empty csv file on the server, not sure why\n",
    "deleting locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Dictionaries to pair user IDs to dataframes of log data\n",
    "# Dictionary linking user names to dataframse with log data\n",
    "user_logs = Dict{Int,DataFrame}()\n",
    "# Dictionary linking user names to dataframes with their transform data\n",
    "user_transforms = Dict{Int,DataFrame}()\n",
    "\n",
    "### Parse the log files\n",
    "# Loop through all the files in the Data directory\n",
    "for filename in readdir(raw\"..\\Data\\RawLogs\", join=true)\n",
    "    # Find substring User_##, use as key to df in dictionary\n",
    "    key = 0\n",
    "    match_obj = match(r\"User_(\\d{1,3})\", filename)\n",
    "    if !isnothing(match_obj)\n",
    "        key = parse(Int, match_obj[1])\n",
    "    else # Skip Guest logs\n",
    "        continue\n",
    "    end\n",
    "\n",
    "    # For the files that contain binary serialized transform data\n",
    "    if endswith(filename, \"TransformTracking.dat\")\n",
    "        df = readtransformfile(filename)\n",
    "        user_transforms[key] = df\n",
    "    end\n",
    "    \n",
    "    # For the general log files\n",
    "    if endswith(filename, \".log\")\n",
    "        df = readlogfile(filename)\n",
    "        user_logs[key] = df\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10×14 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m c_pos_x    \u001b[0m\u001b[1m c_pos_y    \u001b[0m\u001b[1m c_pos_z     \u001b[0m\u001b[1m c_rot_x      \u001b[0m\u001b[1m c_rot_y     \u001b[0m\u001b[1m c_rot_z     \u001b[0m\u001b[1m c_rot_w     \u001b[0m\u001b[1m h_pos_x     \u001b[0m\u001b[1m h_pos_y    \u001b[0m\u001b[1m h_pos_z    \u001b[0m\u001b[1m h_rot_x     \u001b[0m\u001b[1m h_rot_y     \u001b[0m\u001b[1m h_rot_z    \u001b[0m\u001b[1m h_rot_w    \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Float32    \u001b[0m\u001b[90m Float32    \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32      \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32    \u001b[0m\u001b[90m Float32    \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32     \u001b[0m\u001b[90m Float32    \u001b[0m\u001b[90m Float32    \u001b[0m\n",
      "─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │  3.82827     3.62827     0.0          0.0           0.0         -0.0         -0.0         -0.0          1.0         0.0         0.0          0.0         -0.0        -0.0\n",
      "   2 │ -0.0         1.0         0.00109844  -0.00997893   -0.772436     0.192555    -0.0588141   -0.205649     0.626851    0.749204    0.0475877   -0.024524    -0.0225267  -0.116913\n",
      "   3 │  0.104904    0.0400868  -0.986772     0.000458047  -0.00997893  -0.772436     0.192555    -0.0588141   -0.205649    0.626851    0.749204     0.0463464   -0.0251785  -0.0215667\n",
      "   4 │ -0.1181      0.105502    0.0403461   -0.986557      0.016476    -0.00997893  -0.772436     0.192555    -0.0588141  -0.205649    0.626851     0.749204     0.0455333  -0.0253612\n",
      "   5 │ -0.0215214  -0.118967    0.106582     0.0394826    -0.986371     0.0165408   -0.00997893  -0.772436     0.192555   -0.0588141  -0.205649     0.626851     0.749204    0.0452019\n",
      "   6 │ -0.0251266  -0.022235   -0.117863     0.105643      0.0393268   -0.986611     0.216893    -0.00997893  -0.772436    0.192555   -0.0588141   -0.205649     0.626851    0.749204\n",
      "   7 │  0.0373564  -0.0192985  -0.031811    -0.0952535     0.0592005    0.0359299   -0.993041     0.0161283    0.0295338  -0.335227    0.0604605   -0.28391     -0.552359   -0.354699\n",
      "   8 │  0.698916    0.0364127  -0.0190458   -0.0317159    -0.0956059    0.060737     0.0361823   -0.992906     0.0167115   0.0194246  -0.340793     0.00935366  -0.392822   -0.673905\n",
      "   9 │ -0.176112    0.60044     0.0344072   -0.0187806    -0.0315535   -0.0957085    0.0639986    0.0367144   -0.992671    0.0165761   0.021911    -0.342119     0.0173167  -0.397046\n",
      "  10 │ -0.643997   -0.204554    0.621112     0.0323221    -0.0180989   -0.0308101   -0.0930157    0.0659582    0.035612   -0.992839    7.94381e-5   0.0229969   -0.339699    0.0278012\u001b[1m10×5 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m entity          \u001b[0m\u001b[1m tag         \u001b[0m\u001b[1m abstime      \u001b[0m\u001b[1m reltime \u001b[0m\u001b[1m message                           \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m String          \u001b[0m\u001b[90m String      \u001b[0m\u001b[90m Tuple…       \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String                            \u001b[0m\n",
      "─────┼────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ LOGINMANAGER     STATE START  (15, 49, 43)     3.83   Introduction\n",
      "   2 │ LOGINMANAGER     TRACE        (15, 49, 43)     3.83   ToggleControllerRendering()\n",
      "   3 │ DOWNLOADUTILITY  DEBUG        (15, 49, 43)     3.83   Starting download of file $/doc…\n",
      "   4 │ DOWNLOADUTILITY  DEBUG        (15, 49, 43)     3.83   Inside download coroutine, URL:…\n",
      "   5 │ LOGINMANAGER     TRACE        (15, 49, 43)     3.83   SetupIntroAnimation()\n",
      "   6 │ DOWNLOADUTILITY  DEBUG        (15, 49, 43)     3.83   Starting download of file $/doc…\n",
      "   7 │ DOWNLOADUTILITY  DEBUG        (15, 49, 43)     3.83   Inside download coroutine, URL:…\n",
      "   8 │ LOGGER           CONNECT      (15, 49, 43)     0.0    Connect called at 09/20/2022 15…\n",
      "   9 │ LOGGER           TRACE        (15, 49, 43)     0.0    Saving files to persistent data…\n",
      "  10 │ LOGGER           TRACE        (15, 49, 43)     0.0    Sync with transform log 3.828272"
     ]
    }
   ],
   "source": [
    "# Sample of dataframe rows\n",
    "show(first(user_transforms[88], 10), allcols=true)\n",
    "show(first(user_logs[88], 10), allcols=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys(user_logs)\n",
    "    CSV.write(\"../Data/Dataframes/Logs/$(key)_logs.csv\", user_logs[key])\n",
    "end\n",
    "\n",
    "for key in keys(user_transforms)\n",
    "    CSV.write(\"../Data/Dataframes/Transforms/$(key)_transforms.csv\", user_transforms[key])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
